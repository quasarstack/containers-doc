# Serverless

Contrary to what the term "serverless" suggests, servers are of course still required as the basis for your applications. Cloud providers suggest that it is very easy to deploy applications, but require that you prepare and configure several resources like a network, virtual machines, operating systems and load balancers to run a simple web application. The idea of serverless computing is to relieve developers of these complicated tasks. In a nutshell, you can just provide the application code, while the cloud provider chooses the right environment to run your application.

All popular cloud vendors have one or more commercial offerings of proprietary serverless runtimes and a subset of serverless, also known as [Function as a Service (FaaS)](https://www.youtube.com/watch?v=EOIja7yFScs). The cloud provider abstracts the underlying infrastructure, so that developers can deploy software by uploading their code for example as .zip files or providing a container image.

In contrast to other cloud computing models, serverless computing has an even stronger focus on the on-demand provisioning and scaling of applications. Autoscaling is an important core concept of serverless and can include scaling and provisioning based on events like incoming requests. This allows for even more precise billing, which can be based on the events mentioned instead of the widespread time-based billing.

Instead of fully replacing container orchestration platforms or more traditional virtual machines, FaaS systems are often used in combination or as an extension of existing platforms since they allow for a very fast deployment and make for excellent testing and sandbox environments.

While container images are a great standardized way of packing software for FaaS or serverless systems, systems like Knative that are built on top of Kubernetes allow to extend existing platforms with serverless computing abilities. This can be a viable solution for serverless operation in private clouds and on-premises environments. Keep in mind that this can ease the work of a developer, but raise the complexity in operating a cloud platform.

Although there are many advantages to serverless technology, it initially struggled with standardization. Many cloud providers have proprietary offerings that make it difficult to switch between different platforms. To address these problems, the [CloudEvents](https://cloudevents.io/) project was founded and provides a specification of how event data should be structured. Events are the basis for scaling serverless workloads or triggering corresponding functions. The more vendors and tools adopt such a standard, the easier it becomes to use serverless and event-driven architectures on multiple platforms.

Applications that are written for serverless platforms have even stricter requirements for cloud native architecture, but at the same time can benefit most from them. Writing small, stateless applications make them a perfect fit for event or data streams, scheduled tasks, business logic or batch processing.