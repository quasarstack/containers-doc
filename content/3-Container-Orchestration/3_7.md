---
title: Container Orchestration
---

# Container Orchestration Fundamentals

It is fairly easy to run a few containers on your local machine or on a single server, but the way containers are used introduces new challenges regarding the operations of containers. The high efficiency of the concept has resulted in applications and services becoming smaller and smaller and you’ll find that modern applications can consist of a lot of containers.

Having a lot of small containers that are loosely coupled, isolated and independent is the basis for so-called microservice architectures. These small containers are self-contained small parts of business logic that are part of a bigger application.

If you have to manage and deploy large amounts of containers, you quickly get to the point where you need a system that helps with the management of these containers. Problems to be solved can include:

-   Providing compute resources like virtual machines where containers can run on
-   Schedule containers to servers in an efficient way
-   Allocate resources like CPU and memory to containers
-   Manage the availability of containers and replace them if they fail
-   Scale containers if load increases
-   Provide networking to connect containers together
-   Provision storage if containers need to persist data.

Container orchestration systems provide a way to build a cluster of multiple servers and host the containers on top. Most container orchestration systems consist of two parts: a _control plane_ that is responsible for the management of the containers and _worker nodes_ that actually host the containers.

Over the years, there have been several systems that can be used for orchestration, but most of them are no longer of great importance today and the industry has chosen Kubernetes as the standard system to orchestrate containers.